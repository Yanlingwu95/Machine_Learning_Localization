{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111434,
     "status": "ok",
     "timestamp": 1549990822572,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "2oUQ2TpUvvxg",
    "outputId": "8548fffc-f7dc-4d6b-9d32-6c89aa52c3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 113597 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "# 授权绑定Google Drive \n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools \n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null \n",
    "!apt-get update -qq 2>&1 > /dev/null \n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse \n",
    "from google.colab import auth \n",
    "auth.authenticate_user() \n",
    "from oauth2client.client import GoogleCredentials \n",
    "creds = GoogleCredentials.get_application_default() \n",
    "import getpass \n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL \n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5312,
     "status": "ok",
     "timestamp": 1549990836206,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "7H09mQ2zvy1I",
    "outputId": "7760be51-8d7e-4603-8e24-805dc724591d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  qd_LOS_32_berlin_20k.mat  qd_NLOS_32_berlin_20k.mat  v_LOS_32_20k.mat\n"
     ]
    }
   ],
   "source": [
    "# 指定Google Drive云端硬盘的根目录，名为drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "# 指定当前的工作目录\n",
    "import os\n",
    "\n",
    "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
    "os.chdir(\"drive/Acoustic_Localization/keras/data/data_19_1\") \n",
    "\n",
    "\n",
    "# 查看文件目录，是否包含所需的文件\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeEvKC_pv8yd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as KK\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from keras import regularizers\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1549994851789,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "zcTXAbkmv9FK",
    "outputId": "0fb7453f-2b26-4806-9b48-1160710458b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_coeff shape (64, 15000)\n",
      "loc shape (15000, 2)\n",
      "(15000, 4096)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "DDataFile = './data/latest/data/qd_LOS_32_3GPPUMi_15k_SC5.mat'\n",
    "DData = sio.loadmat(DDataFile)\n",
    "#get the coeff data\n",
    "h_coeff = DData['h_coeff_real']\n",
    "location = DData['positions']\n",
    "#split the D_data and location_data and only need the first 2k\n",
    "N = 15000\n",
    "M = 64\n",
    "h_coeff = h_coeff[:,:N]\n",
    "loc = np.transpose(location[:,:N])\n",
    "print(\"h_coeff shape\", h_coeff.shape)\n",
    "print(\"loc shape\", loc.shape)\n",
    "\n",
    "D = np.asmatrix(np.fft.fft(np.eye(M)/np.sqrt(M)))\n",
    "DH = D.H\n",
    "F = np.zeros([N, M * M], dtype = \"complex_\")\n",
    "\n",
    "for i in range(N):\n",
    "    h = np.asmatrix(h_coeff[:, i:i+1])\n",
    "    v = (M **(1 / 6.0) / LA.norm(h, 2)) **(4/3.) * h\n",
    "#     hH = h.H\n",
    "    K = v * v.H\n",
    "    B = D * K * DH\n",
    "    F[i] =B.flatten().A\n",
    "F = np.asarray(F)\n",
    "print(F.shape)\n",
    "print(type(F))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24002209+0.00000000e+00j -0.28100624+2.36810299e-02j\n",
      "  0.54315266-1.12126245e-01j ...  0.34557152-7.00004089e-03j\n",
      " -0.24650808-2.95994059e-02j  0.17335862-2.43011176e-17j]\n"
     ]
    }
   ],
   "source": [
    "#Do normalization here for features !!! \n",
    "# Using std to normalize\n",
    "# F = F - np.mean(F, axis = 0)\n",
    "F = F / np.std(F, axis = 0)\n",
    "print(F[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1549994853099,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "feJtyUD64kQE",
    "outputId": "e1eeffa2-ef9a-44c8-f116-4a016a3416f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft shape (15000, 4096) <class 'numpy.ndarray'>\n",
      "(15000, 4096) (15000, 2)\n",
      "15000 12000 (12000, 4096) (12000, 2)\n",
      "impulses_train shape: (12000, 4096)\n",
      "impulses_test shape: (3000, 4096)\n",
      "location_train shape: (12000, 2)\n",
      "location_test shape: (3000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# real_D = np.real(F)\n",
    "# img_D = np.imag(F)\n",
    "\n",
    "ft = np.absolute(F) # get the absolute of the F data\n",
    "\n",
    "print(\"ft shape\", ft.shape, type(ft))\n",
    "\n",
    "print(F.shape,loc.shape)\n",
    "total, l = F.shape\n",
    "total, d = loc.shape\n",
    "\n",
    "train_length = int(np.floor(total * 0.8))\n",
    "\n",
    "impulses_train = ft[:train_length, :]\n",
    "location_train = loc[:train_length,:]\n",
    "print(total,train_length, impulses_train.shape, location_train.shape)\n",
    "\n",
    "impulses_test = ft[train_length:, :]\n",
    "location_test = loc[train_length:,:]\n",
    "\n",
    " \n",
    "print('impulses_train shape:', impulses_train.shape)\n",
    "print('impulses_test shape:', impulses_test.shape)\n",
    "print('location_train shape:', location_train.shape)\n",
    "print('location_test shape:', location_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kudm6WIl4kpD"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model = keras.Sequential()\n",
    "\n",
    "#model.add(keras.layers.normalization.BatchNormalization())\n",
    "\n",
    "model.add(Dense(1024, activation = 'relu'))   #the hidden layer number \n",
    "\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu')) \n",
    "\n",
    "model.add(Dense(d, activation = 'linear'))  # None is different from 'linear'      ### the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1549995351598,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "7XEJ_0M74ksR",
    "outputId": "228a8b7b-42ab-4142-e77d-baefa0ec5849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 4096) (12000, 2)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Compilation\n",
    "loss_func = 'mean_squared_error'   #   categorical_crossentropy(bad)   mean_squared_error\n",
    "opt_func = keras.optimizers.Adam() #'Adam'  lr=0.001  #  RMSprop() sgd()  Adadelta()   Adam\n",
    "\n",
    "model.compile(loss = loss_func, \n",
    "              optimizer = opt_func\n",
    "             )\n",
    "\n",
    "print(impulses_train.shape, location_train.shape)\n",
    "print(type(impulses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194835,
     "status": "ok",
     "timestamp": 1549995547367,
     "user": {
      "displayName": "Yanling Wu",
      "photoUrl": "https://lh6.googleusercontent.com/-u8By8ce8J3g/AAAAAAAAAAI/AAAAAAAAAAc/Kc_mVS4EgIg/s64/photo.jpg",
      "userId": "12488151021031492401"
     },
     "user_tz": 300
    },
    "id": "tmEK37644kvL",
    "outputId": "b7e7cca0-2d58-48d4-81b9-ecf45bbcdd6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 4096) (12000, 2)\n",
      "(3000, 4096) (3000, 2)\n",
      "Train on 10800 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "10800/10800 [==============================] - 9s 818us/step - loss: 21575.6233 - val_loss: 7311.9209\n",
      "Epoch 2/200\n",
      "10800/10800 [==============================] - 8s 741us/step - loss: 6513.4829 - val_loss: 6666.6457\n",
      "Epoch 3/200\n",
      "10800/10800 [==============================] - 8s 752us/step - loss: 5738.2456 - val_loss: 5642.0549\n",
      "Epoch 4/200\n",
      "10800/10800 [==============================] - 8s 738us/step - loss: 5319.2176 - val_loss: 5426.7167\n",
      "Epoch 5/200\n",
      "10800/10800 [==============================] - 8s 741us/step - loss: 4991.2999 - val_loss: 5051.8108\n",
      "Epoch 6/200\n",
      "10800/10800 [==============================] - 9s 787us/step - loss: 4808.3812 - val_loss: 4787.5746\n",
      "Epoch 7/200\n",
      "10800/10800 [==============================] - 9s 812us/step - loss: 4585.6158 - val_loss: 4670.7175\n",
      "Epoch 8/200\n",
      "10800/10800 [==============================] - 10s 884us/step - loss: 4543.8161 - val_loss: 4663.2137\n",
      "Epoch 9/200\n",
      "10800/10800 [==============================] - 9s 863us/step - loss: 4366.2287 - val_loss: 4850.0884\n",
      "Epoch 10/200\n",
      "10800/10800 [==============================] - 9s 819us/step - loss: 4289.7105 - val_loss: 4679.3136\n",
      "Epoch 11/200\n",
      "10800/10800 [==============================] - 9s 831us/step - loss: 4153.7788 - val_loss: 4635.4074\n",
      "Epoch 12/200\n",
      "10800/10800 [==============================] - 8s 786us/step - loss: 4058.8478 - val_loss: 4566.9671\n",
      "Epoch 13/200\n",
      "10800/10800 [==============================] - 8s 739us/step - loss: 3977.7606 - val_loss: 4541.3322\n",
      "Epoch 14/200\n",
      "10800/10800 [==============================] - 8s 722us/step - loss: 3872.0914 - val_loss: 4585.4869\n",
      "Epoch 15/200\n",
      "10800/10800 [==============================] - 8s 769us/step - loss: 3738.5807 - val_loss: 4630.4165\n",
      "Epoch 16/200\n",
      "10800/10800 [==============================] - 9s 817us/step - loss: 3684.9211 - val_loss: 4494.0450\n",
      "Epoch 17/200\n",
      "10800/10800 [==============================] - 9s 826us/step - loss: 3648.5889 - val_loss: 4414.3931\n",
      "Epoch 18/200\n",
      "10800/10800 [==============================] - 8s 768us/step - loss: 3506.7246 - val_loss: 4656.2809\n",
      "Epoch 19/200\n",
      "10800/10800 [==============================] - 9s 794us/step - loss: 3488.0943 - val_loss: 4852.6603\n",
      "Epoch 20/200\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 3387.7633 - val_loss: 4747.5467\n",
      "Epoch 21/200\n",
      "10800/10800 [==============================] - 8s 742us/step - loss: 3316.5915 - val_loss: 5208.9564\n",
      "Epoch 22/200\n",
      "10800/10800 [==============================] - 9s 792us/step - loss: 3205.7053 - val_loss: 4805.6841\n",
      "Epoch 23/200\n",
      "10800/10800 [==============================] - 9s 841us/step - loss: 3106.6094 - val_loss: 4867.3792\n",
      "Epoch 24/200\n",
      "10800/10800 [==============================] - 9s 793us/step - loss: 3088.7309 - val_loss: 4736.5473\n",
      "Epoch 25/200\n",
      "10800/10800 [==============================] - 9s 819us/step - loss: 3063.6949 - val_loss: 4874.5228\n",
      "Epoch 26/200\n",
      "10800/10800 [==============================] - 9s 822us/step - loss: 2929.8152 - val_loss: 4985.8289\n",
      "Epoch 27/200\n",
      "10800/10800 [==============================] - 9s 852us/step - loss: 2915.2921 - val_loss: 4956.7976\n",
      "Epoch 28/200\n",
      "10800/10800 [==============================] - 9s 820us/step - loss: 2874.9166 - val_loss: 4749.6346\n",
      "Epoch 29/200\n",
      "10800/10800 [==============================] - 9s 809us/step - loss: 2743.0736 - val_loss: 4919.3709\n",
      "Epoch 30/200\n",
      "10800/10800 [==============================] - 8s 753us/step - loss: 2695.2011 - val_loss: 4968.6279\n",
      "Epoch 31/200\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 2621.0636 - val_loss: 4893.2377\n",
      "Epoch 32/200\n",
      "10800/10800 [==============================] - 9s 792us/step - loss: 2560.3853 - val_loss: 5182.0131\n",
      "Epoch 33/200\n",
      "10800/10800 [==============================] - 9s 809us/step - loss: 2518.3055 - val_loss: 4951.6500\n",
      "Epoch 34/200\n",
      "10800/10800 [==============================] - 9s 799us/step - loss: 2426.1985 - val_loss: 4953.3695\n",
      "Epoch 35/200\n",
      "10800/10800 [==============================] - 9s 818us/step - loss: 2387.1876 - val_loss: 5271.6701\n",
      "Epoch 36/200\n",
      "10800/10800 [==============================] - 9s 838us/step - loss: 2315.7528 - val_loss: 5123.8398\n",
      "Epoch 37/200\n",
      "10800/10800 [==============================] - 10s 888us/step - loss: 2238.6822 - val_loss: 5334.9281\n",
      "Epoch 38/200\n",
      "10800/10800 [==============================] - 9s 807us/step - loss: 2300.2608 - val_loss: 5048.6569\n",
      "Epoch 39/200\n",
      "10800/10800 [==============================] - 9s 842us/step - loss: 2177.5716 - val_loss: 5209.7250\n",
      "Epoch 40/200\n",
      "10800/10800 [==============================] - 9s 852us/step - loss: 2075.1798 - val_loss: 5183.7636\n",
      "Epoch 41/200\n",
      "10800/10800 [==============================] - 9s 861us/step - loss: 2106.2654 - val_loss: 5149.4961\n",
      "Epoch 42/200\n",
      "10800/10800 [==============================] - 9s 812us/step - loss: 2053.1921 - val_loss: 5344.4016\n",
      "Epoch 43/200\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 1978.9383 - val_loss: 5393.5390\n",
      "Epoch 44/200\n",
      "10800/10800 [==============================] - 9s 806us/step - loss: 1951.9167 - val_loss: 5505.2538\n",
      "Epoch 45/200\n",
      "10800/10800 [==============================] - 9s 847us/step - loss: 1913.6055 - val_loss: 5488.9008\n",
      "Epoch 46/200\n",
      "10800/10800 [==============================] - 9s 848us/step - loss: 1863.6603 - val_loss: 5251.7979\n",
      "Epoch 47/200\n",
      "10800/10800 [==============================] - 9s 842us/step - loss: 1844.0112 - val_loss: 5355.9203\n",
      "Epoch 48/200\n",
      "10800/10800 [==============================] - 9s 827us/step - loss: 1853.8624 - val_loss: 5290.5027\n",
      "Epoch 49/200\n",
      "10800/10800 [==============================] - 9s 854us/step - loss: 1777.4053 - val_loss: 5353.7436\n",
      "Epoch 50/200\n",
      "10800/10800 [==============================] - 9s 859us/step - loss: 1766.2219 - val_loss: 5576.8069\n",
      "Epoch 51/200\n",
      "10800/10800 [==============================] - 9s 845us/step - loss: 1670.6873 - val_loss: 5319.6106\n",
      "Epoch 52/200\n",
      "10800/10800 [==============================] - 9s 814us/step - loss: 1726.5405 - val_loss: 5372.0755\n",
      "Epoch 53/200\n",
      "10800/10800 [==============================] - 9s 819us/step - loss: 1669.8035 - val_loss: 5487.3872\n",
      "Epoch 54/200\n",
      "10800/10800 [==============================] - 9s 815us/step - loss: 1665.5846 - val_loss: 5589.7740\n",
      "Epoch 55/200\n",
      "10800/10800 [==============================] - 9s 822us/step - loss: 1623.7912 - val_loss: 5395.2547\n",
      "Epoch 56/200\n",
      "10800/10800 [==============================] - 9s 825us/step - loss: 1706.2901 - val_loss: 5513.4752\n",
      "Epoch 57/200\n",
      "10800/10800 [==============================] - 9s 850us/step - loss: 1557.7430 - val_loss: 5502.9237\n",
      "Epoch 58/200\n",
      "10800/10800 [==============================] - 9s 806us/step - loss: 1474.2400 - val_loss: 5473.2425\n",
      "Epoch 59/200\n",
      "10800/10800 [==============================] - 8s 787us/step - loss: 1498.1514 - val_loss: 5728.1294\n",
      "Epoch 60/200\n",
      "10800/10800 [==============================] - 9s 835us/step - loss: 1439.9212 - val_loss: 5592.8772\n",
      "Epoch 61/200\n",
      "10800/10800 [==============================] - 9s 795us/step - loss: 1381.5713 - val_loss: 5628.0334\n",
      "Epoch 62/200\n",
      "10800/10800 [==============================] - 8s 779us/step - loss: 1429.6177 - val_loss: 5489.2784\n",
      "Epoch 63/200\n",
      "10800/10800 [==============================] - 9s 789us/step - loss: 1350.3982 - val_loss: 5621.3639\n",
      "Epoch 64/200\n",
      "10800/10800 [==============================] - 9s 835us/step - loss: 1322.9951 - val_loss: 5582.4466\n",
      "Epoch 65/200\n",
      "10800/10800 [==============================] - 9s 812us/step - loss: 1350.6145 - val_loss: 5571.9660\n",
      "Epoch 66/200\n",
      "10800/10800 [==============================] - 9s 843us/step - loss: 1284.8940 - val_loss: 5590.3729\n",
      "Epoch 67/200\n",
      "10800/10800 [==============================] - 9s 820us/step - loss: 1256.7317 - val_loss: 5692.6527\n",
      "Epoch 68/200\n",
      "10800/10800 [==============================] - 8s 782us/step - loss: 1207.8995 - val_loss: 5581.1487\n",
      "Epoch 69/200\n",
      "10800/10800 [==============================] - 9s 789us/step - loss: 1246.3930 - val_loss: 5751.2385\n",
      "Epoch 70/200\n",
      "10800/10800 [==============================] - 9s 815us/step - loss: 1195.5495 - val_loss: 5505.5138\n",
      "Epoch 71/200\n",
      "10800/10800 [==============================] - 9s 853us/step - loss: 1195.9526 - val_loss: 5534.7636\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800/10800 [==============================] - 9s 819us/step - loss: 1148.4925 - val_loss: 5467.8132\n",
      "Epoch 73/200\n",
      "10800/10800 [==============================] - 9s 832us/step - loss: 1129.6624 - val_loss: 5685.8585\n",
      "Epoch 74/200\n",
      "10800/10800 [==============================] - 10s 933us/step - loss: 1114.2509 - val_loss: 5668.0608\n",
      "Epoch 75/200\n",
      "10800/10800 [==============================] - 10s 924us/step - loss: 1149.2226 - val_loss: 5525.9003\n",
      "Epoch 76/200\n",
      "10800/10800 [==============================] - 9s 856us/step - loss: 1137.6088 - val_loss: 5596.0369\n",
      "Epoch 77/200\n",
      "10800/10800 [==============================] - 9s 874us/step - loss: 1050.7778 - val_loss: 5433.8643\n",
      "Epoch 78/200\n",
      "10800/10800 [==============================] - 9s 856us/step - loss: 1037.4940 - val_loss: 5500.6071\n",
      "Epoch 79/200\n",
      "10800/10800 [==============================] - 9s 859us/step - loss: 1057.3756 - val_loss: 5647.5774\n",
      "Epoch 80/200\n",
      "10800/10800 [==============================] - 9s 842us/step - loss: 1054.5964 - val_loss: 5613.1520\n",
      "Epoch 81/200\n",
      "10800/10800 [==============================] - 9s 839us/step - loss: 1027.0286 - val_loss: 5430.6541\n",
      "Epoch 82/200\n",
      "10800/10800 [==============================] - 9s 823us/step - loss: 1046.0524 - val_loss: 5665.7350\n",
      "Epoch 83/200\n",
      "10800/10800 [==============================] - 9s 824us/step - loss: 1002.5234 - val_loss: 5818.7703\n",
      "Epoch 84/200\n",
      "10800/10800 [==============================] - 9s 815us/step - loss: 1016.7345 - val_loss: 5915.8955\n",
      "Epoch 85/200\n",
      "10800/10800 [==============================] - 9s 840us/step - loss: 959.9337 - val_loss: 5474.8271\n",
      "Epoch 86/200\n",
      "10800/10800 [==============================] - 9s 833us/step - loss: 976.1146 - val_loss: 5470.4173\n",
      "Epoch 87/200\n",
      "10800/10800 [==============================] - 9s 834us/step - loss: 910.0430 - val_loss: 5545.0712\n",
      "Epoch 88/200\n",
      "10800/10800 [==============================] - 9s 830us/step - loss: 898.6504 - val_loss: 5916.3465\n",
      "Epoch 89/200\n",
      "10800/10800 [==============================] - 9s 846us/step - loss: 877.4288 - val_loss: 5663.9538\n",
      "Epoch 90/200\n",
      "10800/10800 [==============================] - 9s 804us/step - loss: 905.2124 - val_loss: 5491.2983\n",
      "Epoch 91/200\n",
      "10800/10800 [==============================] - 9s 822us/step - loss: 878.4340 - val_loss: 5558.0794\n",
      "Epoch 92/200\n",
      "10800/10800 [==============================] - 10s 915us/step - loss: 881.8541 - val_loss: 5625.2159\n",
      "Epoch 93/200\n",
      "10800/10800 [==============================] - 10s 896us/step - loss: 880.3668 - val_loss: 5694.3847\n",
      "Epoch 94/200\n",
      "10800/10800 [==============================] - 9s 870us/step - loss: 949.9981 - val_loss: 5856.5606\n",
      "Epoch 95/200\n",
      "10800/10800 [==============================] - 9s 840us/step - loss: 898.4129 - val_loss: 5761.9262\n",
      "Epoch 96/200\n",
      "10800/10800 [==============================] - 9s 846us/step - loss: 854.3833 - val_loss: 5703.3564\n",
      "Epoch 97/200\n",
      "10800/10800 [==============================] - 9s 845us/step - loss: 856.2926 - val_loss: 5527.3916\n",
      "Epoch 98/200\n",
      "10800/10800 [==============================] - 10s 969us/step - loss: 873.6515 - val_loss: 7004.0347\n",
      "Epoch 99/200\n",
      "10800/10800 [==============================] - 10s 883us/step - loss: 811.3880 - val_loss: 5742.2767\n",
      "Epoch 100/200\n",
      "10800/10800 [==============================] - 9s 825us/step - loss: 795.0926 - val_loss: 5502.2497\n",
      "Epoch 101/200\n",
      "10800/10800 [==============================] - 9s 866us/step - loss: 844.5293 - val_loss: 5459.7058\n",
      "Epoch 102/200\n",
      "10800/10800 [==============================] - 9s 796us/step - loss: 805.0011 - val_loss: 5597.9487\n",
      "Epoch 103/200\n",
      "10800/10800 [==============================] - 9s 819us/step - loss: 757.0167 - val_loss: 5705.7576\n",
      "Epoch 104/200\n",
      "10800/10800 [==============================] - 9s 814us/step - loss: 830.0663 - val_loss: 5765.9108\n",
      "Epoch 105/200\n",
      "10800/10800 [==============================] - 9s 841us/step - loss: 744.0975 - val_loss: 5687.7312\n",
      "Epoch 106/200\n",
      "10800/10800 [==============================] - 9s 857us/step - loss: 748.0120 - val_loss: 5797.9605\n",
      "Epoch 107/200\n",
      "10800/10800 [==============================] - 9s 827us/step - loss: 694.4339 - val_loss: 5635.5592\n",
      "Epoch 108/200\n",
      "10800/10800 [==============================] - 9s 851us/step - loss: 700.8837 - val_loss: 5875.7300\n",
      "Epoch 109/200\n",
      "10800/10800 [==============================] - 9s 830us/step - loss: 702.5047 - val_loss: 5685.8481\n",
      "Epoch 110/200\n",
      "10800/10800 [==============================] - 9s 809us/step - loss: 701.0429 - val_loss: 5536.3125\n",
      "Epoch 111/200\n",
      "10800/10800 [==============================] - 9s 815us/step - loss: 721.5509 - val_loss: 5859.4465\n",
      "Epoch 112/200\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 681.9843 - val_loss: 5716.2347\n",
      "Epoch 113/200\n",
      "10800/10800 [==============================] - 8s 756us/step - loss: 656.0108 - val_loss: 5574.2810\n",
      "Epoch 114/200\n",
      "10800/10800 [==============================] - 9s 795us/step - loss: 695.9518 - val_loss: 5615.4503\n",
      "Epoch 115/200\n",
      "10800/10800 [==============================] - 9s 822us/step - loss: 647.2389 - val_loss: 5557.0876\n",
      "Epoch 116/200\n",
      "10800/10800 [==============================] - 9s 813us/step - loss: 662.2751 - val_loss: 5578.8502\n",
      "Epoch 117/200\n",
      "10800/10800 [==============================] - 9s 831us/step - loss: 617.2869 - val_loss: 5542.6973\n",
      "Epoch 118/200\n",
      "10800/10800 [==============================] - 9s 853us/step - loss: 626.9960 - val_loss: 5673.3457\n",
      "Epoch 119/200\n",
      "10800/10800 [==============================] - 9s 836us/step - loss: 678.9162 - val_loss: 5579.8387\n",
      "Epoch 120/200\n",
      "10800/10800 [==============================] - 9s 866us/step - loss: 659.6181 - val_loss: 5650.8712\n",
      "Epoch 121/200\n",
      "10800/10800 [==============================] - 9s 838us/step - loss: 618.0888 - val_loss: 5620.3105\n",
      "Epoch 122/200\n",
      "10800/10800 [==============================] - 10s 888us/step - loss: 595.8631 - val_loss: 5457.9424\n",
      "Epoch 123/200\n",
      "10800/10800 [==============================] - 10s 919us/step - loss: 620.7872 - val_loss: 5683.8000\n",
      "Epoch 124/200\n",
      "10800/10800 [==============================] - 10s 909us/step - loss: 644.1987 - val_loss: 5536.1957\n",
      "Epoch 125/200\n",
      "10800/10800 [==============================] - 9s 874us/step - loss: 609.4416 - val_loss: 5403.5053\n",
      "Epoch 126/200\n",
      " 2000/10800 [====>.........................] - ETA: 7s - loss: 568.0785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d28f02063dd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m \u001b[1;31m#0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#                     validation_data=(impulses_test,location_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                    )\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model, iterating\n",
    "print(impulses_train.shape, location_train.shape)\n",
    "print(impulses_test.shape, location_test.shape)\n",
    "\n",
    "history = model.fit(impulses_train, location_train,\n",
    "                    batch_size = 100, # 50 -> 52138; 20->52088\n",
    "                    epochs = 200,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.1 #0.2\n",
    "#                     validation_data=(impulses_test,location_test)\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2cGEuunv9NV"
   },
   "outputs": [],
   "source": [
    "#make prediction\n",
    "loc_prediction = model.predict(impulses_test)\n",
    "print(loc_prediction.shape)\n",
    "print(location_test.shape)\n",
    "\n",
    "#The training result\n",
    "loss = model.evaluate(impulses_test, location_test, verbose=1)\n",
    "print ('Test loss & mean_absolute_error: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1pmarl7K33F"
   },
   "outputs": [],
   "source": [
    "#plot the loss data\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['loss'],'r',label = 'loss')\n",
    "plt.plot(history.history['val_loss'],'b', label = 'val_loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# ax1.set_title('Location Scatter Plot')\n",
    "# ax1.scatter(loc_prediction[:,0],loc_prediction[:,1],c = 'r',marker = 'o', label = 'predic')\n",
    "# ax1.scatter(location_test[:,0],location_test[:,1],c = 'b',marker = 'x', label = 'test')\n",
    "# plt.legend()\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4rE2-OwK33J"
   },
   "outputs": [],
   "source": [
    "#calculate the mean of error distance\n",
    "err = loc_prediction - location_test\n",
    "x = err[:,:1]\n",
    "y = err[:,1:]\n",
    "\n",
    "err_dis = np.sqrt(np.square(x)+np.square(y))\n",
    "err_min = np.min(err_dis)\n",
    "err_max = np.max(err_dis)\n",
    "err_avg = np.mean(err_dis)\n",
    "print(\"error distance is \", err_avg)\n",
    "print(\"max error distance is \", err_max)\n",
    "print(\"min error distance is \", err_min)\n",
    "#set the value of x, y, z\n",
    "x,y,z = location_test[:,:1],location_test[:,1:2],err_dis\n",
    "\n",
    "#plot the 2D image of error\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(err_dis, 35, range = [50,230])\n",
    "plt.xlabel(\"error\")\n",
    "plt.ylabel(\"number\")\n",
    "plt.title(\"distance error histogram range [50, 230]\") \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(err_dis, 35, range = [0, 50])\n",
    "plt.xlabel(\"error\")\n",
    "plt.ylabel(\"number\")\n",
    "plt.title(\"distance error histogram range [0, 50]\") \n",
    "plt.savefig(\"hist.png\")\n",
    "\n",
    "plt.figure(3)\n",
    "#plt.subplot(2,1,1)\n",
    "plt.plot(err_dis)\n",
    "plt.title(\"The mean distance error distribution\")\n",
    "plt.xlabel(\"location\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Qq0e7IQzmBv"
   },
   "outputs": [],
   "source": [
    "#plot 3D image\n",
    "ax = plt.subplot(111,projection='3d')\n",
    "ax.scatter(x,y,z,c='r')\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Error\")\n",
    "plt.title(\"The mean distance error of 3D Iamge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fiGo2Hx1zoky"
   },
   "outputs": [],
   "source": [
    "#draw the \"heatmap\" of error\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "ax3 = fig.add_subplot(111)\n",
    "cm = plt.cm.get_cmap('RdYlBu_r') #Accent  RdYlBu_r RdYlBu  Blues_r  Greens  YlOrBr_r\n",
    "\n",
    "sc = ax3.scatter(x,y,c = z, marker = 'o', label = 'test',alpha=0.9, cmap=cm)\n",
    "plt.colorbar(sc)\n",
    "ax3.set_xlabel(\"x\")\n",
    "ax3.set_ylabel(\"y\")\n",
    "plt.title(\"The mean distance error of 'heat map'\")\n",
    "plt.savefig(\"heat_map.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0et2st-X3Wjd"
   },
   "outputs": [],
   "source": [
    "#plot small scale error map\n",
    "\n",
    "err_map = np.hstack((location_test, err_dis))\n",
    "err_map = pd.DataFrame(err_map, columns=['x', 'y', 'err'])\n",
    "err_map_300 = err_map[err_map['x']<300]\n",
    "err_map_300 = err_map_300[err_map_300['y']<150]\n",
    "err_map_300 = err_map_300[err_map_300['y']>-150]\n",
    "# np.array(err_map_300['x'])\n",
    "print('the mean of error %f'% err_map_300['err'].mean())\n",
    "print('the max of error %f'% err_map_300['err'].max())\n",
    "print('the max of error %f'% err_map_300['err'].min())\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax4 = fig.add_subplot(111)\n",
    "cm = plt.cm.get_cmap('RdYlBu_r') #Accent  RdYlBu_r RdYlBu  Blues_r  Greens  YlOrBr_r\n",
    "sc = ax4.scatter(np.array(err_map_300['x']),np.array(err_map_300['y']),c = np.array(err_map_300['err']), marker = 'o', label = 'test',alpha=0.9, cmap=cm)\n",
    "plt.colorbar(sc)\n",
    "ax4.set_xlabel(\"x\")\n",
    "ax4.set_ylabel(\"y\")\n",
    "plt.title(\"The mean distance error of 'heat map'\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzOdeQ-k6FY-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#plot the 2D image of error\n",
    "plt.figure(1)\n",
    "#plt.subplot(2,1,2)\n",
    "plt.hist(np.array(err_map_300['err']), bins =  range(0,45,1)) \n",
    "plt.xlabel(\"error\")\n",
    "plt.ylabel(\"number\")\n",
    "plt.title(\"distance error histogram\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion :\n",
    "\n",
    "number of layers| batch size | epoch | volidation | loss| error(average) | error(min)|\n",
    "--|--|--|--|--|--|--|\n",
    "3| 100| 100 | 0.1|1314.788985|22.5|0.23|\n",
    "4| 100|100|0.1|1273.8396|24.5| 0.12|\n",
    "batchnormalization 4| 100|100|0.1|overfitting|\n",
    "batchnormalization 3| 100|100|0.1|82.426|8.4811|0.168|(BEST)\n",
    "- three layers with mse batch size 100, epoch 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "19-Extraction-feature.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
